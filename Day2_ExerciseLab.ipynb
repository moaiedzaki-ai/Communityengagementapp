{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image.png](https://i.imgur.com/a3uAqnb.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# **\ud83c\udfaf Machine Learning Exercise: Student Performance Prediction**\n\n---\n\n## **\ud83d\udccb Exercise Overview**\n\nBuild a complete ML pipeline to predict student performance with **three tasks**:\n\n1. **Regression**: Predict final exam score (0-100)\n2. **Binary Classification**: Pass/Fail (\u226560 = Pass)\n3. **Multi-Class Classification**: Grade (A, B, C, D, F)\n\n**Features:**\n- study_hours, attendance, previous_score, sleep_hours, extracurricular\n\n**Difficulty:** \ud83d\udfe2 Easy | \ud83d\udfe1 Medium | \ud83d\udd34 Hard\n\n**Total: 28 TODOs**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **1\ufe0f\u20e3 Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import clear_output\n%pip install tqdm -q\nclear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe2 TODO 1: Create Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Complete dataset creation\nnp.random.seed(42)\nn_samples = 500\n\n# TODO: Create features (Hint: np.random.uniform)\nstudy_hours = np.random.uniform(5, 40, n_samples)  # TODO: Your turn for others\nattendance = # TODO: range 50-100\nprevious_score = # TODO: range 40-95\nsleep_hours = # TODO: range 4-9\nextracurricular = # TODO: np.random.choice([0, 1], n_samples)\n\n# Create target\nfinal_score = (0.4 * study_hours + 0.3 * attendance + 0.2 * previous_score + \n               0.1 * sleep_hours * 5 + 3 * extracurricular + \n               np.random.normal(0, 5, n_samples))\nfinal_score = np.clip(final_score, 0, 100)\n\n# TODO: Create DataFrame\ndf = pd.DataFrame({\n    'study_hours': study_hours,\n    # TODO: Add other columns\n})\n\nprint(f\"\u2713 Created dataset with {len(df)} samples\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **2\ufe0f\u20e3 EDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe2 TODO 2: Dataset Info**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Display dataset info\n# df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe1 TODO 3: Missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Check for missing values\nmissing = # TODO: df.isnull().sum()\nprint(\"Missing values:\")\n# print(missing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe1 TODO 4: Visualize Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create histogram of final_score\nplt.figure(figsize=(10, 6))\n# TODO: plt.hist(df['final_score'], bins=30)\n# plt.xlabel('Final Score')\n# plt.ylabel('Frequency')\n# plt.title('Score Distribution')\nplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **3\ufe0f\u20e3 Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe2 TODO 5: Binary Target**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create pass_fail (1 if score>=60, else 0)\ndf['pass_fail'] = # TODO: np.where(df['final_score'] >= 60, 1, 0)\nprint(df['pass_fail'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe1 TODO 6: Multi-Class Target**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create grade column\ndef assign_grade(score):\n    if score >= 90: return 'A'\n    elif score >= 80: return # TODO\n    elif score >= 70: return # TODO\n    # TODO: Complete for D and F\n    \ndf['grade'] = df['final_score'].apply(assign_grade)\nprint(df['grade'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe1 TODO 7: Encode Grades**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Map grades to numbers\ngrade_mapping = {'A': 4, 'B': 3, # TODO: Complete mapping\ndf['grade_encoded'] = df['grade'].map(grade_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **4\ufe0f\u20e3 Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe1 TODO 8: Feature Scaling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n\n# TODO: Select features\nX = df[['study_hours', 'attendance', # TODO: Add others]]\ny_reg = df['final_score']\ny_binary = df['pass_fail']\ny_multi = df['grade_encoded']\n\n# TODO: Scale features\nscaler = StandardScaler()\nX_scaled = # TODO: scaler.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **5\ufe0f\u20e3 Part A: Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udd34 TODO 9: MSE Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Implement MSE\ndef mean_squared_error(y_true, y_pred):\n    # TODO: MSE = mean((y_true - y_pred)^2)\n    return # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udd34 TODO 10: Gradient Descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Complete gradient descent\ndef gradient_descent_regression(X, y, lr=0.01, n_iters=1000):\n    m, n = X.shape\n    theta = np.zeros(n)\n    losses = []\n    \n    for _ in tqdm(range(n_iters)):\n        # TODO: y_pred = X @ theta\n        # TODO: loss = mean_squared_error(y, y_pred)\n        # TODO: gradient = (1/m) * X.T @ (y_pred - y)\n        # TODO: theta -= lr * gradient\n        pass\n    \n    return theta, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe1 TODO 11: Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n\n# TODO: Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y_reg, test_size=0.2, random_state=42)\n\n# TODO: Add bias\nX_train_bias = np.c_[np.ones(len(X_train)), X_train]\nX_test_bias = # TODO\n\n# TODO: Train\ntheta, losses = gradient_descent_regression(X_train_bias, y_train, lr=0.1, n_iters=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe2 TODO 12: Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import r2_score\n\n# TODO: Predict and calculate RMSE, R\u00b2\ny_pred = # TODO\nrmse = # TODO: np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = # TODO\n\nprint(f\"RMSE: {rmse:.2f}, R\u00b2: {r2:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **6\ufe0f\u20e3 Part B: Binary Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udd34 TODO 13: Sigmoid Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Implement sigmoid\ndef sigmoid(z):\n    return # TODO: 1 / (1 + np.exp(-z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udd34 TODO 14: Binary Cross-Entropy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Implement BCE\ndef binary_cross_entropy(y_true, y_pred, eps=1e-15):\n    y_pred = np.clip(y_pred, eps, 1-eps)\n    return # TODO: -mean(y_true*log(y_pred) + (1-y_true)*log(1-y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udd34 TODO 15: Logistic Gradient Descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Complete logistic regression\ndef gradient_descent_logistic(X, y, lr=0.01, n_iters=1000):\n    m, n = X.shape\n    theta = np.zeros(n)\n    losses = []\n    \n    for _ in tqdm(range(n_iters)):\n        # TODO: z = X @ theta\n        # TODO: y_pred = sigmoid(z)\n        # TODO: loss = binary_cross_entropy(y, y_pred)\n        # TODO: gradient = (1/m) * X.T @ (y_pred - y)\n        # TODO: theta -= lr * gradient\n        pass\n    \n    return theta, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe1 TODO 16: Train & Evaluate Binary Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n\n# TODO: Split, train, predict\nX_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n    X_scaled, y_binary, test_size=0.2, random_state=42)\n\n# TODO: Add bias, train, predict, evaluate\n# accuracy = accuracy_score(y_test_b, y_pred_b)\n# print(f\"Accuracy: {accuracy:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **7\ufe0f\u20e3 Part C: Multi-Class Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udd34 TODO 17: Softmax Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Implement softmax\ndef softmax(z):\n    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n    return # TODO: exp_z / sum(exp_z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udd34 TODO 18: Categorical Cross-Entropy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Implement CCE\ndef categorical_cross_entropy(y_true, y_pred, eps=1e-15):\n    y_pred = np.clip(y_pred, eps, 1-eps)\n    return # TODO: -mean(sum(y_true * log(y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udd34 TODO 19: One-Hot Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Implement one-hot encoding\ndef one_hot_encode(y, num_classes):\n    n = len(y)\n    one_hot = np.zeros((n, num_classes))\n    # TODO: one_hot[np.arange(n), y] = 1\n    return one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udd34 TODO 20: Softmax Gradient Descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Complete softmax regression\ndef gradient_descent_softmax(X, y, num_classes, lr=0.01, n_iters=1000):\n    m, n = X.shape\n    theta = np.zeros((n, num_classes))\n    y_onehot = one_hot_encode(y, num_classes)\n    losses = []\n    \n    for _ in tqdm(range(n_iters)):\n        # TODO: z = X @ theta\n        # TODO: y_pred = softmax(z)\n        # TODO: loss = categorical_cross_entropy(y_onehot, y_pred)\n        # TODO: gradient = (1/m) * X.T @ (y_pred - y_onehot)\n        # TODO: theta -= lr * gradient\n        pass\n    \n    return theta, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **\ud83d\udfe1 TODO 21: Train & Evaluate Multi-Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Split, train, predict\nX_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n    X_scaled, y_multi, test_size=0.2, random_state=42)\n\nnum_classes = len(np.unique(y_multi))\n\n# TODO: Add bias, train, predict, calculate accuracy\n# accuracy_m = accuracy_score(y_test_m, y_pred_m)\n# print(f\"Accuracy: {accuracy_m:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# **\ud83c\udf93 Completion Summary**\n\n## **Congratulations! \ud83c\udf89**\n\nYou've completed **28 TODOs** covering:\n- \u2705 Data loading & EDA\n- \u2705 Feature engineering\n- \u2705 Linear Regression (MSE, Gradient Descent)\n- \u2705 Binary Classification (Sigmoid, BCE)\n- \u2705 Multi-Class Classification (Softmax, CCE)\n\n**Expected Results:**\n- Regression: RMSE ~5-8, R\u00b2 ~0.85-0.95\n- Binary: Accuracy ~85-95%\n- Multi-Class: Accuracy ~70-85%\n\n**Next Steps:**\n- Compare with sklearn implementations\n- Try different hyperparameters\n- Add cross-validation\n- Implement regularization\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}